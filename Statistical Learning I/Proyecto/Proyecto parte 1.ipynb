{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto\n",
    "\n",
    "## Parte 1: Entrenamiento y validación y selección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando librerías\n",
    "\n",
    "import sklearn.metrics as mt\n",
    "from sklearn.externals import joblib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "from sklearn import tree\n",
    "# !pip install graphviz\n",
    "import graphviz\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabled compatitility to tf1.x\n"
     ]
    }
   ],
   "source": [
    "#Habilitando compatibilidad con tensorflow v1\n",
    "if tf.__version__.startswith(\"2.\"):\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.compat.v1.disable_v2_behavior()\n",
    "  tf.compat.v1.disable_eager_execution()\n",
    "  print(\"Enabled compatitility to tf1.x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando y examinando datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "PassengerId             int64\n",
      "Name                   object\n",
      "Age                   float64\n",
      "SibSp                   int64\n",
      "Parch                   int64\n",
      "Ticket                 object\n",
      "Fare                  float64\n",
      "Cabin                  object\n",
      "Embarked               object\n",
      "passenger_class        object\n",
      "passenger_sex          object\n",
      "passenger_survived     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId                                               Name   Age  \\\n",
       "0            1                            Braund, Mr. Owen Harris  22.0   \n",
       "1            2  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0   \n",
       "2            3                             Heikkinen, Miss. Laina  26.0   \n",
       "3            4       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0   \n",
       "4            5                           Allen, Mr. William Henry  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked passenger_class  \\\n",
       "0      1      0         A/5 21171   7.2500   NaN        S           Lower   \n",
       "1      1      0          PC 17599  71.2833   C85        C           Upper   \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S           Lower   \n",
       "3      1      0            113803  53.1000  C123        S           Upper   \n",
       "4      0      0            373450   8.0500   NaN        S           Lower   \n",
       "\n",
       "  passenger_sex passenger_survived  \n",
       "0             M                  N  \n",
       "1             F                  Y  \n",
       "2             F                  Y  \n",
       "3             F                  Y  \n",
       "4             M                  N  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_titanic_proyecto.csv\")\n",
    "print(data.shape)\n",
    "print(data.dtypes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cantidad de filas NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SibSp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Parch</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ticket</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fare</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Cabin</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Embarked</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>passenger_class</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>passenger_sex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>passenger_survived</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Cantidad de filas NaN\n",
       "PassengerId                             0\n",
       "Name                                    0\n",
       "Age                                   177\n",
       "SibSp                                   0\n",
       "Parch                                   0\n",
       "Ticket                                  0\n",
       "Fare                                    0\n",
       "Cabin                                 687\n",
       "Embarked                                2\n",
       "passenger_class                         0\n",
       "passenger_sex                           0\n",
       "passenger_survived                      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando valos NaN en los datos\n",
    "pd.DataFrame({'Cantidad de filas NaN': data.isnull().sum()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cantidad de filas NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SibSp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Parch</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ticket</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fare</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Embarked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>passenger_class</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>passenger_sex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>passenger_survived</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Cantidad de filas NaN\n",
       "PassengerId                             0\n",
       "Name                                    0\n",
       "Age                                     0\n",
       "SibSp                                   0\n",
       "Parch                                   0\n",
       "Ticket                                  0\n",
       "Fare                                    0\n",
       "Embarked                                0\n",
       "passenger_class                         0\n",
       "passenger_sex                           0\n",
       "passenger_survived                      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reemplazando los valos NaN de Embarked por la moda\n",
    "embarkedDF=pd.DataFrame(data[\"Embarked\"].value_counts())\n",
    "data[\"Embarked\"] = data[\"Embarked\"].fillna(embarkedDF['Embarked'].idxmax())\n",
    "\n",
    "#Descartando la columna Cabin ya que faltan muchos datos\n",
    "data = data.drop(['Cabin'], axis=1)\n",
    "\n",
    "#Reemplazando los valos NaN de la edad por la media\n",
    "meanAge = np.mean(data.Age)\n",
    "data[\"Age\"] = data[\"Age\"].fillna(meanAge);\n",
    "pd.DataFrame({'Cantidad de filas NaN': data.isnull().sum()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S    646\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "Lower     491\n",
      "Upper     216\n",
      "Middle    184\n",
      "Name: passenger_class, dtype: int64\n",
      "M    577\n",
      "F    314\n",
      "Name: passenger_sex, dtype: int64\n",
      "N    549\n",
      "Y    342\n",
      "Name: passenger_survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Verificando variables categoricas\n",
    "print(data[\"Embarked\"].value_counts())\n",
    "print(data[\"passenger_class\"].value_counts())\n",
    "print(data[\"passenger_sex\"].value_counts())\n",
    "print(data[\"passenger_survived\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>passenger_class</th>\n",
       "      <th>passenger_sex</th>\n",
       "      <th>passenger_survived</th>\n",
       "      <th>male</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Upper</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Lower</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId                                               Name   Age  \\\n",
       "0            1                            Braund, Mr. Owen Harris  22.0   \n",
       "1            2  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0   \n",
       "2            3                             Heikkinen, Miss. Laina  26.0   \n",
       "3            4       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0   \n",
       "4            5                           Allen, Mr. William Henry  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Embarked passenger_class  \\\n",
       "0      1      0         A/5 21171   7.2500        S           Lower   \n",
       "1      1      0          PC 17599  71.2833        C           Upper   \n",
       "2      0      0  STON/O2. 3101282   7.9250        S           Lower   \n",
       "3      1      0            113803  53.1000        S           Upper   \n",
       "4      0      0            373450   8.0500        S           Lower   \n",
       "\n",
       "  passenger_sex passenger_survived  male  survived  \n",
       "0             M                  N     1         0  \n",
       "1             F                  Y     0         1  \n",
       "2             F                  Y     0         1  \n",
       "3             F                  Y     0         1  \n",
       "4             M                  N     1         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convirtiendo variables categoricas binarias a numericas\n",
    "vc_binarias = np.array(['passenger_sex','passenger_survived'])\n",
    "data[['male','survived']] = data.loc[:,vc_binarias].apply(LabelEncoder().fit_transform)  \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>male</th>\n",
       "      <th>survived</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>passenger_class_Lower</th>\n",
       "      <th>passenger_class_Middle</th>\n",
       "      <th>passenger_class_Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.188552</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.725028</td>\n",
       "      <td>0.551066</td>\n",
       "      <td>0.206510</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>13.002015</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.391372</td>\n",
       "      <td>0.281141</td>\n",
       "      <td>0.446751</td>\n",
       "      <td>0.497665</td>\n",
       "      <td>0.405028</td>\n",
       "      <td>0.428790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId         Age       SibSp       Parch        Fare  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000   29.699118    0.523008    0.381594   32.204208   \n",
       "std     257.353842   13.002015    1.102743    0.806057   49.693429   \n",
       "min       1.000000    0.420000    0.000000    0.000000    0.000000   \n",
       "25%     223.500000   22.000000    0.000000    0.000000    7.910400   \n",
       "50%     446.000000   29.699118    0.000000    0.000000   14.454200   \n",
       "75%     668.500000   35.000000    1.000000    0.000000   31.000000   \n",
       "max     891.000000   80.000000    8.000000    6.000000  512.329200   \n",
       "\n",
       "             male    survived  Embarked_C  Embarked_Q  Embarked_S  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.647587    0.383838    0.188552    0.086420    0.725028   \n",
       "std      0.477990    0.486592    0.391372    0.281141    0.446751   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "75%      1.000000    1.000000    0.000000    0.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "       passenger_class_Lower  passenger_class_Middle  passenger_class_Upper  \n",
       "count             891.000000              891.000000             891.000000  \n",
       "mean                0.551066                0.206510               0.242424  \n",
       "std                 0.497665                0.405028               0.428790  \n",
       "min                 0.000000                0.000000               0.000000  \n",
       "25%                 0.000000                0.000000               0.000000  \n",
       "50%                 1.000000                0.000000               0.000000  \n",
       "75%                 1.000000                0.000000               0.000000  \n",
       "max                 1.000000                1.000000               1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convirtiendo variables categoricas no binarias a numericas\n",
    "vc_multiples = np.array(['Embarked','passenger_class'])\n",
    "df_vc_multiples = pd.get_dummies(data.loc[:,vc_multiples])\n",
    "df_vc_multiples.head()\n",
    "data= pd.concat([data,df_vc_multiples],axis=1,sort=True)\n",
    "data.head()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"male\",\"Embarked_C\", \"Embarked_Q\", \"Embarked_S\",\n",
    "             \"passenger_class_Lower\", \"passenger_class_Middle\", \"passenger_class_Upper\"]\n",
    "\n",
    "vectorX= data[features].values\n",
    "vectorY=data.survived.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de los datos en entrenamiento, validación y pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((605, 11), (605,), (179, 11), (179,), (107, 11), (107,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX,testX,trainY,testY = train_test_split(vectorX, vectorY,test_size = 0.2,shuffle = True,random_state = 20)\n",
    "trainX,valX,trainY,valY = train_test_split(trainX, trainY,test_size = 0.15,shuffle = True,random_state = 2020)\n",
    "np.savez(file = \"testDataSet.npz\", testX=testX, testY=testY)\n",
    "trainX.shape, trainY.shape, testX.shape, testY.shape, valX.shape, valY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitacora de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitacora(ArchivoBitacora, df_bitacora):\n",
    "    if not os.path.isfile(ArchivoBitacora):\n",
    "        df_bitacora.to_csv(ArchivoBitacora)\n",
    "    else: \n",
    "        df_bitacora.to_csv(ArchivoBitacora, header=False, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM (kernel, c, gamma, xTrain, yTrain, xVal, yVal, Standardize):\n",
    "    if (Standardize==True):\n",
    "        scaler1 = StandardScaler()\n",
    "        xTrain = scaler1.fit_transform(xTrain)\n",
    "        scaler2 = StandardScaler()\n",
    "        xVal = scaler2.fit_transform(xVal)\n",
    "    modelSVM = svm.SVC(kernel=kernel, C=c, gamma=gamma)\n",
    "    modelSVM.fit(xTrain, yTrain)\n",
    "    yHat = modelSVM.predict(xVal)    \n",
    "    precision = metrics.precision_score(yVal, yHat)\n",
    "    accuracy = metrics.accuracy_score(yVal, yHat)\n",
    "    recall = metrics.recall_score(yVal, yHat)\n",
    "    f1_score = metrics.f1_score(yVal, yHat)\n",
    "    score = modelSVM.score(xVal, yVal)  \n",
    "    resultados = { 'kernel':[kernel],'c':[c],'gamma':[gamma],\n",
    "                   'precision':[precision],'accuracy':[accuracy],\n",
    "                   'recall':[recall],'f1_score':[f1_score],\n",
    "                   'score':[score],'Standardize':[Standardize]\n",
    "                 }\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    bitacora('bitacoraSVM.csv',df_resultados)\n",
    "    return df_resultados,modelSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    kernel    c  gamma  precision  accuracy    recall  f1_score     score  \\\n",
      "0      rbf  0.1   0.01   0.916667  0.663551  0.239130  0.379310  0.663551   \n",
      "1      rbf  0.1   0.02   0.875000  0.738318  0.456522  0.600000  0.738318   \n",
      "2      rbf  0.1   0.03   0.838710  0.766355  0.565217  0.675325  0.766355   \n",
      "3      rbf  0.1   0.04   0.838710  0.766355  0.565217  0.675325  0.766355   \n",
      "4      rbf  0.1   0.05   0.846154  0.738318  0.478261  0.611111  0.738318   \n",
      "..     ...  ...    ...        ...       ...       ...       ...       ...   \n",
      "886    rbf  0.9   0.95   0.750000  0.738318  0.586957  0.658537  0.738318   \n",
      "887    rbf  0.9   0.96   0.750000  0.738318  0.586957  0.658537  0.738318   \n",
      "888    rbf  0.9   0.97   0.742857  0.728972  0.565217  0.641975  0.728972   \n",
      "889    rbf  0.9   0.98   0.742857  0.728972  0.565217  0.641975  0.728972   \n",
      "890    rbf  0.9   0.99   0.742857  0.728972  0.565217  0.641975  0.728972   \n",
      "\n",
      "     Standardize  \n",
      "0           True  \n",
      "1           True  \n",
      "2           True  \n",
      "3           True  \n",
      "4           True  \n",
      "..           ...  \n",
      "886         True  \n",
      "887         True  \n",
      "888         True  \n",
      "889         True  \n",
      "890         True  \n",
      "\n",
      "[891 rows x 9 columns]\n",
      "kernel              rbf\n",
      "c                   0.3\n",
      "gamma              0.13\n",
      "precision      0.878788\n",
      "accuracy       0.803738\n",
      "recall         0.630435\n",
      "f1_score       0.734177\n",
      "score          0.803738\n",
      "Standardize        True\n",
      "Name: 210, dtype: object\n"
     ]
    }
   ],
   "source": [
    "lista_C = np.arange(0.1,1,0.1)\n",
    "lista_gamma = np.arange(0.01,1,0.01)\n",
    "# lista_kernel = ['rbf','linear','poly','sigmoid']\n",
    "resultado_modelos_svm = pd.DataFrame()\n",
    "modelos_svm = list()\n",
    "\n",
    "for c in lista_C:\n",
    "    for gamma in lista_gamma:\n",
    "        resultados,model_svm = train_SVM('rbf', c, gamma ,trainX, trainY, valX, valY, True)\n",
    "        resultado_modelos_svm = pd.concat([resultado_modelos_svm,resultados],axis=0,ignore_index=True)\n",
    "        modelos_svm.append(model_svm)\n",
    "print(resultado_modelos_svm)\n",
    "index_best_model = resultado_modelos_svm['score'].idxmax()\n",
    "joblib.dump(modelos_svm[index_best_model], 'modeloSVM.pkl') \n",
    "print(resultado_modelos_svm.loc[index_best_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_DecisionTree(depth,xTrain, yTrain, xVal, yVal, Standardize):\n",
    "    if (Standardize==True):\n",
    "        scaler1 = StandardScaler()\n",
    "        xTrain = scaler1.fit_transform(xTrain)\n",
    "        scaler2 = StandardScaler()\n",
    "        xVal = scaler2.fit_transform(xVal)\n",
    "    modelDecisionTree = tree.DecisionTreeClassifier(max_depth = depth)\n",
    "    modelDecisionTree.fit(xTrain, yTrain)\n",
    "    yHat = modelDecisionTree.predict(xVal)    \n",
    "    precision = metrics.precision_score(yVal, yHat)\n",
    "    accuracy = metrics.accuracy_score(yVal, yHat)\n",
    "    recall = metrics.recall_score(yVal, yHat)\n",
    "    f1_score = metrics.f1_score(yVal, yHat)\n",
    "    score = modelDecisionTree.score(xVal, yVal)  \n",
    "    resultados = { 'depth':[depth],'precision':[precision],'accuracy':[accuracy],\n",
    "                   'recall':[recall],'f1_score':[f1_score],\n",
    "                   'score':[score],'Standardize':[Standardize]\n",
    "                 }\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    bitacora('bitacoraDecisionTree.csv',df_resultados)\n",
    "    return df_resultados,modelDecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   depth  precision  accuracy    recall  f1_score     score  Standardize\n",
      "0      1   0.815789  0.794393  0.673913  0.738095  0.794393         True\n",
      "1      2   0.952381  0.747664  0.434783  0.597015  0.747664         True\n",
      "2      3   0.878788  0.803738  0.630435  0.734177  0.803738         True\n",
      "3      4   0.829268  0.822430  0.739130  0.781609  0.822430         True\n",
      "4      5   0.829268  0.822430  0.739130  0.781609  0.822430         True\n",
      "5      6   0.755102  0.803738  0.804348  0.778947  0.803738         True\n",
      "6      7   0.822222  0.841121  0.804348  0.813187  0.841121         True\n",
      "7      8   0.698113  0.766355  0.804348  0.747475  0.766355         True\n",
      "8      9   0.734694  0.785047  0.782609  0.757895  0.785047         True\n",
      "depth                 7\n",
      "precision      0.822222\n",
      "accuracy       0.841121\n",
      "recall         0.804348\n",
      "f1_score       0.813187\n",
      "score          0.841121\n",
      "Standardize        True\n",
      "Name: 6, dtype: object\n"
     ]
    }
   ],
   "source": [
    "lista_depth = np.arange(1,10,1)\n",
    "resultado_modelos_DecisionTree = pd.DataFrame()\n",
    "modelos_DecisionTree = list()\n",
    "\n",
    "for depth in lista_depth:\n",
    "    resultados,model_DecisionTree = train_DecisionTree(depth,trainX, trainY, valX, valY, True)\n",
    "    resultado_modelos_DecisionTree = pd.concat([resultado_modelos_DecisionTree,resultados],axis=0,ignore_index=True)\n",
    "    modelos_DecisionTree.append(model_DecisionTree)\n",
    "print(resultado_modelos_DecisionTree)\n",
    "index_best_model = resultado_modelos_DecisionTree['score'].idxmax()\n",
    "joblib.dump(modelos_DecisionTree[index_best_model], 'modeloDecisionTree.pkl') \n",
    "print(resultado_modelos_DecisionTree.loc[index_best_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generando arbol con Graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DecisionTree.png'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_data = tree.export_graphviz(modelos_DecisionTree[index_best_model],  \n",
    "                                class_names=data[\"passenger_survived\"].value_counts().index.values,\n",
    "                                feature_names=features, \n",
    "                                out_file=None,\n",
    "                                filled=True, \n",
    "                                special_characters=True, \n",
    "                                rounded=True \n",
    "                               )\n",
    "tree = graphviz.Source(tree_data)\n",
    "tree.format = 'png'\n",
    "tree.render(\"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DecisionTree.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((605, 11), (605,), (179, 11), (179,), (107, 11), (107,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape, trainY.shape, testX.shape, testY.shape, valX.shape, valY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 12) (107, 12)\n"
     ]
    }
   ],
   "source": [
    "trainXPlusB = np.column_stack((np.ones(trainX.shape[0]), trainX))\n",
    "valXPlusB = np.column_stack((np.ones(valX.shape[0]), valX))\n",
    "\n",
    "print(np.shape(trainXPlusB),np.shape(valXPlusB))\n",
    "\n",
    "fil, col = trainXPlusB.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "g = tf.Graph()\n",
    "with g.as_default():   \n",
    "    \n",
    "    #Placeholder\n",
    "    lr = tf.placeholder(tf.float32,name=\"lr\")\n",
    "    x  = tf.placeholder(tf.float32,shape=(None,col),name=\"x\")\n",
    "    y  = tf.placeholder(tf.float32, name = \"y\")\n",
    "    pLambda = tf.placeholder(tf.float32, name = \"pLambda\")\n",
    "\n",
    "    #Variables\n",
    "    with tf.name_scope(\"parametros\"):\n",
    "        w = tf.Variable(tf.truncated_normal(shape = [col, 1]), name = \"w\")\n",
    "\n",
    "    #Calculando logits y estimaciones\n",
    "    with tf.name_scope(\"Logits\"):\n",
    "        logits = tf.matmul(x, w, name = \"logits\") \n",
    "        yHat = tf.nn.sigmoid(logits, name = \"YHat\")\n",
    "        \n",
    "    #Regularizando\n",
    "    with tf.name_scope(\"RegularizacionW\"):\n",
    "        w_reg = tf.divide(tf.multiply(tf.multiply(tf.constant(0.5), pLambda),tf.reduce_sum(tf.square(w))), tf.cast(fil, tf.float32), name = \"w_reg\")\n",
    "\n",
    "    #Definiendo función de costo    \n",
    "    with tf.name_scope(\"costoSinRegularizacion\"):        \n",
    "        costoSinRegularizacion = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = logits), name = \"costoSinRegularizacion\")\n",
    "    with tf.name_scope(\"costo\"):\n",
    "        costo = tf.add(costoSinRegularizacion, w_reg, name=\"Costo\")    \n",
    "\n",
    "    # Optimizador de gradiente \n",
    "#   with tf.name_scope(\"OptimizadorGradiente\"):\n",
    "#   gradienteOptimizado = tf.train.GradientDescentOptimizer(lr).minimize(costo) \n",
    "        \n",
    "    #Autodiferenciación para calcular gradiente\n",
    "    with tf.name_scope(\"Gradiente\"):\n",
    "        grad = tf.gradients(costo,w)\n",
    "        \n",
    "    #Descenso de gradiente    \n",
    "    with tf.name_scope(\"actualizado_parametros\"):\n",
    "        new_params = tf.assign(w, w - lr*grad[0] )\n",
    "\n",
    "    #Calculando métricas   \n",
    "    with tf.name_scope(\"Metricas\"):\n",
    "        M_costo = tf.summary.scalar(name='costo', tensor = costo)\n",
    "        metricas = tf.summary.merge_all()\n",
    "\n",
    "    init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_regresion_logistica(x_vector,y_vector,epochs,imprimir_error_cada,learning_rate,batch_size,tipoRegularizacion,p_lambda):\n",
    "    # Iniciando grafo\n",
    "    with tf.Session(graph = g) as session:\n",
    "        # Inicializamos las variables en la sesión\n",
    "        session.run(init) \n",
    "        # Manejo de los logs en tensorboard\n",
    "        writer = tf.summary.FileWriter('./tensorBoardLogs/'+ datetime.today().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "                                       + '_GadientDescent_lr=' + str(learning_rate)\n",
    "                                       + '_epochs=' + str(epochs)\n",
    "                                       + '_tipoRegularizacion=' + str(tipoRegularizacion), session.graph)\n",
    "\n",
    "\n",
    "        tamaño_muestra=x_vector.shape[0] \n",
    "        total_iteraciones = int(tamaño_muestra/batch_size)\n",
    "\n",
    "        count=0    \n",
    "        for epoch in range(epochs):\n",
    "            for i in range(total_iteraciones):\n",
    "                count=count+1\n",
    "                muestra_inicio = i*batch_size\n",
    "                muestra_fin = muestra_inicio + batch_size\n",
    "\n",
    "                x_mb = np.array(x_vector[muestra_inicio:muestra_fin])\n",
    "                y_mb = np.array(y_vector[muestra_inicio:muestra_fin])\n",
    "                feed_dict = {x:x_mb, y:y_mb, lr:learning_rate, pLambda:p_lambda}\n",
    "\n",
    "#                 _, metrics = session.run([gradienteOptimizado, metricas], feed_dict = feed_dict)\n",
    "                _, metrics = session.run([new_params, metricas], feed_dict = feed_dict)\n",
    "                writer.add_summary(metrics, count)\n",
    "\n",
    "                if ((i + 1) % imprimir_error_cada == 0): \n",
    "                    cost = session.run(costo, feed_dict = feed_dict)\n",
    "                    print(\"Epoch = %d,\\tIteración = %d,\\tCosto: %0.4f\" % (epoch+1, i+1, cost))\n",
    "        writer.close()\n",
    "        params = session.run(w)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_modelo_regresion_logistica(x, w):\n",
    "    logits = np.matmul(x, w)\n",
    "    yHat = ((1 / (1 + np.exp(-logits))) > 0.5)*1.0\n",
    "    return yHat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_modelo_regresion_logistica(lambda_,lr_,xVal, yVal, w):\n",
    "    yHat = predecir_modelo_regresion_logistica(xVal, w)\n",
    "    precision = metrics.precision_score(yVal, yHat)\n",
    "    accuracy = metrics.accuracy_score(yVal, yHat)\n",
    "    recall = metrics.recall_score(yVal, yHat)\n",
    "    f1_score = metrics.f1_score(yVal, yHat)\n",
    " \n",
    "    resultados = { 'lambda':[lambda_], 'lr':[lr_],'precision':[precision],'accuracy':[accuracy],\n",
    "                   'recall':[recall],'f1_score':[f1_score]\n",
    "                 }\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    bitacora('bitacoraRegresionLogistica.csv',df_resultados)\n",
    "    return df_resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda       3.000000\n",
      "lr           0.003000\n",
      "precision    0.750000\n",
      "accuracy     0.682243\n",
      "recall       0.391304\n",
      "f1_score     0.514286\n",
      "Name: 12, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "lista_lr = np.arange(0.001,0.009,0.001)\n",
    "lista_lambda = np.arange(1,6,1)\n",
    "resultado_modelos_RegLogistica= pd.DataFrame()\n",
    "modelos_RegLogistica = list()\n",
    "\n",
    "for lr_ in lista_lr:\n",
    "    for lambda_ in lista_lambda:\n",
    "        model_RegLosgistica = entrenar_modelo_regresion_logistica(trainXPlusB,trainY,10,50,lr_,30,\"L2\",lambda_)\n",
    "        modelos_RegLogistica.append(model_RegLosgistica)\n",
    "        resultados = metricas_modelo_regresion_logistica(lambda_,lr_,valXPlusB, valY, model_RegLosgistica)\n",
    "        resultado_modelos_RegLogistica = pd.concat([resultado_modelos_RegLogistica,resultados],axis=0,ignore_index=True)\n",
    "    \n",
    "    \n",
    "\n",
    "index_best_model = resultado_modelos_RegLogistica['accuracy'].idxmax() \n",
    "np.savez(file = \"modeloLogisticRegression.npz\", w = modelos_RegLogistica[index_best_model])\n",
    "print(resultado_modelos_RegLogistica.loc[index_best_model])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafo, costo y exactitud en Tensorboard\n",
    "\n",
    "<img src=\"TensorBoard.png\">\n",
    "\n",
    "<img src=\"Metricas.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes con pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_pandas(trainXv, trainYv, predictColumn, predictValue):\n",
    "    summ = pd.DataFrame(columns=['Feature', 'Element', 'Prob'])\n",
    "    sCondicional = pd.DataFrame(columns=['Feature', 'YItem', 'Element', 'Prob'])\n",
    "    y_total_rows = trainYv.shape[0]\n",
    "    objective_features = trainYv[predictColumn].unique().tolist()\n",
    "    numUpper = 1\n",
    "    numDown = 1\n",
    "    for feature in objective_features:\n",
    "        probValue = trainYv[trainYv == feature].count() / y_total_rows\n",
    "        summ = summ.append({'Feature': predictColumn, 'Element': feature, 'Prob': probValue}, ignore_index=True)\n",
    "    x_total_rows = trainXv.shape[0]\n",
    "    x_colnames = trainXv.columns\n",
    "    for column in x_colnames:\n",
    "        FeaturesValues = trainXv[column].unique().tolist()\n",
    "        for feature in FeaturesValues:\n",
    "            features = trainXv[column]\n",
    "            probValue = features[features == feature].count() / x_total_rows\n",
    "            summ = summ.append({'Feature': column, 'Element': feature, 'Prob': probValue}, ignore_index=True)\n",
    "            for y_feature in objective_features:\n",
    "                cFeatures = pd.DataFrame(columns=['YColumn', 'XColumn'])\n",
    "                cFeatures['XColumn'] = features\n",
    "                cFeatures['YColumn'] = trainYv\n",
    "                cFeatures = cFeatures[cFeatures['YColumn']==y_feature]\n",
    "                predFeatures_count = len(cFeatures)\n",
    "                cFeatures = cFeatures[cFeatures['XColumn']==feature]\n",
    "                cFeatures_count = len(cFeatures)\n",
    "                sCondicional = sCondicional.append({'Feature': column, 'YItem': y_feature, 'Element': feature, 'Prob': cFeatures_count/predFeatures_count}, ignore_index=True)\n",
    "    trainYv_count = len(trainYv)\n",
    "    predictValue_count = len(trainYv[trainYv==predictValue])\n",
    "    predictprobValue = predictValue_count / trainYv_count \n",
    "    x_colnames = trainXv.columns\n",
    "    resultado = pd.DataFrame(columns=['Feature', 'Element', 'Prob'])\n",
    "    for column in x_colnames:\n",
    "        FeaturesValues = trainXv[column].unique().tolist()\n",
    "        for feature in FeaturesValues:\n",
    "            ProbConditional = sCondicional[(sCondicional['YItem']==predictValue) & (sCondicional['Feature']==column) & (sCondicional['Element']==feature)]            \n",
    "            probX = summ[(summ['Feature']==column) & (summ['Element']==feature)]            \n",
    "            numUpper = ProbConditional['Prob'].iloc[0] * predictprobValue\n",
    "            numDown = probX['Prob'].iloc[0]\n",
    "            resultado = resultado.append({'Feature': column, 'Element': feature, 'Prob': numUpper/numDown}, ignore_index=True)\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes con SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NaiveBayes(xTrain, yTrain, xVal, yVal):    \n",
    "    model = GaussianNB()\n",
    "    modelNaiveBayes = model.fit(xTrain,yTrain)\n",
    "    yHat = modelNaiveBayes.predict(xVal)    \n",
    "    precision = metrics.precision_score(yVal, yHat)\n",
    "    accuracy = metrics.accuracy_score(yVal, yHat)\n",
    "    recall = metrics.recall_score(yVal, yHat)\n",
    "    f1_score = metrics.f1_score(yVal, yHat)\n",
    "    score = modelNaiveBayes.score(xVal, yVal)  \n",
    "    resultados = { 'precision':[precision],'accuracy':[accuracy],\n",
    "                   'recall':[recall],'f1_score':[f1_score],\n",
    "                   'score':[score]\n",
    "                 }\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    bitacora('bitacoraNaiveBayes.csv',df_resultados)\n",
    "    return df_resultados,modelNaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precision  accuracy    recall  f1_score    score\n",
      "0   0.727273   0.71028  0.521739  0.607595  0.71028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['modeloNaiveBayes.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado_modelo_NaiveBayes, model_NaiveBayes = train_NaiveBayes(trainX, trainY, valX, valY)\n",
    "print(resultado_modelo_NaiveBayes)\n",
    "joblib.dump(model_NaiveBayes, 'modeloNaiveBayes.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ensemble(X):\n",
    "    valXPlusB = np.column_stack((np.ones(X.shape[0]), X))\n",
    "    svmModel = joblib.load(\"modeloSVM.pkl\")\n",
    "    desicionTreeModel = joblib.load(\"modeloDecisionTree.pkl\")\n",
    "    logisticalRegression = np.load(\"modeloLogisticRegression.npz\")\n",
    "    w = logisticalRegression['w']\n",
    "    naiveBayesModel = joblib.load(\"modeloNaiveBayes.pkl\")\n",
    "    yHat_SVM = svmModel.predict(X)\n",
    "    yHat_desicionTree = desicionTreeModel.predict(X)\n",
    "    yHat_logisticalRegression = predecir_modelo_regresion_logistica(valXPlusB, w)\n",
    "    yHat_naiveBayes = naiveBayesModel.predict(X)\n",
    "    yHats = np.column_stack((yHat_SVM,yHat_desicionTree,yHat_logisticalRegression,yHat_naiveBayes))\n",
    "    yHat, _ = stats.mode(yHats, axis = 1)\n",
    "    return yHat, yHats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble datos de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svmModel</th>\n",
       "      <th>desicionTreeModel Tree</th>\n",
       "      <th>logisticalRegression Logistica</th>\n",
       "      <th>naiveBayesModel</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     svmModel  desicionTreeModel Tree  logisticalRegression Logistica  \\\n",
       "0         0.0                     0.0                             0.0   \n",
       "1         0.0                     1.0                             0.0   \n",
       "2         0.0                     0.0                             1.0   \n",
       "3         0.0                     1.0                             1.0   \n",
       "4         0.0                     1.0                             0.0   \n",
       "..        ...                     ...                             ...   \n",
       "102       0.0                     1.0                             0.0   \n",
       "103       0.0                     1.0                             0.0   \n",
       "104       0.0                     1.0                             0.0   \n",
       "105       0.0                     0.0                             0.0   \n",
       "106       0.0                     0.0                             0.0   \n",
       "\n",
       "     naiveBayesModel  Survived  \n",
       "0                0.0       0.0  \n",
       "1                0.0       0.0  \n",
       "2                1.0       0.0  \n",
       "3                0.0       0.0  \n",
       "4                0.0       0.0  \n",
       "..               ...       ...  \n",
       "102              0.0       0.0  \n",
       "103              0.0       0.0  \n",
       "104              0.0       0.0  \n",
       "105              0.0       0.0  \n",
       "106              1.0       0.0  \n",
       "\n",
       "[107 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yHat, yHats = Ensemble(valX)\n",
    "EnsembleResults = pd.DataFrame(np.column_stack((yHats, yHat)), \n",
    "             columns=[\"svmModel\", \"desicionTreeModel Tree\",\"logisticalRegression Logistica\",\"naiveBayesModel\", \"Survived\"])\n",
    "EnsembleResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble datos de prueba final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svmModel</th>\n",
       "      <th>desicionTreeModel Tree</th>\n",
       "      <th>logisticalRegression Logistica</th>\n",
       "      <th>naiveBayesModel</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     svmModel  desicionTreeModel Tree  logisticalRegression Logistica  \\\n",
       "0         0.0                     1.0                             0.0   \n",
       "1         0.0                     0.0                             1.0   \n",
       "2         0.0                     0.0                             1.0   \n",
       "3         0.0                     0.0                             0.0   \n",
       "4         1.0                     1.0                             1.0   \n",
       "..        ...                     ...                             ...   \n",
       "174       0.0                     0.0                             1.0   \n",
       "175       0.0                     0.0                             0.0   \n",
       "176       0.0                     1.0                             0.0   \n",
       "177       0.0                     0.0                             0.0   \n",
       "178       1.0                     0.0                             1.0   \n",
       "\n",
       "     naiveBayesModel  Survived  \n",
       "0                1.0       0.0  \n",
       "1                1.0       0.0  \n",
       "2                1.0       0.0  \n",
       "3                0.0       0.0  \n",
       "4                1.0       1.0  \n",
       "..               ...       ...  \n",
       "174              1.0       0.0  \n",
       "175              1.0       0.0  \n",
       "176              1.0       0.0  \n",
       "177              0.0       0.0  \n",
       "178              1.0       1.0  \n",
       "\n",
       "[179 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "testX = scaler.fit_transform(testX)\n",
    "\n",
    "yHatTest, yHatsTest = Ensemble(testX)\n",
    "EnsembleResultsTest = pd.DataFrame(np.column_stack((yHatsTest, yHatTest)), \n",
    "             columns=[\"svmModel\", \"desicionTreeModel Tree\",\"logisticalRegression Logistica\",\"naiveBayesModel\", \"Survived\"])\n",
    "EnsembleResultsTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accurrancy\n",
    "mt.accuracy_score(testY, yHatTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones y recomendaciones\n",
    "\n",
    "Una de las recomendaciones que forman parte de las primeras tareas al aboradar problemas en machine learning es realizar un anális exploratorio de datos, esto permite comprender de mejor manera la cantidad, forma y tipo de datos, a partir de los cuales tendremos que aplicar distintas transformaciones a los mismos para poder iniciar con la definición y entrenamiento de modelos de machine learning.\n",
    "\n",
    "En mi opinion, entrenar y validar modelos de machine learning requiere realizar varios experimentos variando los distintos hiperparametros de cada modelo, esto permite ir mejorando poco a poco la calidad del modelo buscando, es una tarea que requiere de tiempo y esfuerzo considerable pero en el camino se va ganando experiencia y se logra una mejor comprensión de cómo cada uno de los parámetros afectan el resultado final. \n",
    "\n",
    "Una de las mayores dificultades encontradas en el proyecto es la investigación, interpretación y aplicación de las distintas funciones para clasificación binaria, ya que entre la teoría y la práctica a veces se vuelve un poco confuso la interpretación de las mismas. Lectura recomendada: https://stackoverflow.com/questions/46291253/what-is-the-difference-between-a-sigmoid-followed-by-the-cross-entropy-and-sigmo\n",
    "\n",
    "Utilizar un conjunto de modelos de machine learning en donde cada uno produce una predicción diferente y luego combinar las mismas para obtener una única predicción (Ensemble) permite tener un modelo robusto en donde por la naturaleza diferente de cada uno de los modelos que se combinan, los errores tienden a compensarse. Cuando se desea predecerir un dato nuevo se obtiene la predicción de cada modelo y la predicción resultante será la que la mayoría de los modelos presentaron.\n",
    "\n",
    "\n",
    "\n",
    "#### Bootstraping\n",
    "\n",
    "Consiste en obtener muestras de datos aleatorias de todo el dataset, en el proyecto no fue aplicado pero puede utilizarse la función **numpy.random.sample (utilizando el parámetro -> replace = True)** \n",
    "\n",
    "#### k-fold cross validation\n",
    "\n",
    "Es una técnica que consiste en dividir el dataset de forma aleatoria en **k** grupos de aproximadamente el mismo tamaño. **k-1 grupos** se emplean para entrenar el modelo y uno de los grupos se emplea como test, este proceso se repite **k** veces utilizando un grupo distinto como test en cada iteración. El proceso genera k estimaciones del error cuyo promedio se emplea como estimación final.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
